---
title: "Reviving Thenables"
nextLink: "./3-chunks"
---
import CodeBlock from "../../../components/CodeBlock.astro"
import InfoBox from "../../../components/InfoBox.astro"
import IFrame from "../../../components/IFrame.astro"

import Chunk from "../../../components/demos/rscs/2-chunks/Chunk.mdx"

## Introduction

As we delve deeper into the depths of React Server Components (_RSC_), I'm going do my best to give you all the background information you need to truly understand each part of the code. Hopefully, the last chapter cemented the basic concept of _React Server Components_ (RSC) in your mind and helped you see how it differs from _Server Side Rendering_ (_SSR_). It's important to fully grasp this distinction as we move forward. 

This is not the only background knowledge that you need, however. Before we get into the heart of the _React Server Component_ codebase, it's essential that we understand the types of problems that it was built to solve. Beyond that, _RSC_'s adopt a whole host of clever tricks which use some of the more obscure features of the Web Platform. So, we'll need to cover some of these advanced concepts first to understand how they work.

In this chapter, we're going to be discussing asynchronous code. I mean, have you ever thought about what that really means? We hear words like single-threaded and event loop thrown around a lot, but it seems like relatively few developers take the time to understand what's really happening under the hood.

To answer this question, we'll weave a narrative based on the history of the Web itself. We'll frame it as the journey from primitive events to modern APIs. The majority of this chapter will focus on [_promises_](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Using_promises), how they work, and how React uses them.

However, to fully understand the React internals, there are a few more things we need to cover. So, we will also explore _JSON [Replacer](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify#the_replacer_parameter) and [Reviver](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/parse#the_reviver_parameter)_ functions. These are used to customize the serialization of JavaScript objects. React uses them to pull a few cool tricks in their streaming process. We'll discuss how they work and why they're used.

Finally, we'll briefly examine how the fetch method encapsulates the evolution of many of these concepts as we attempt to tie together all of these disparate but intertwined threads. It's such a simple interface for easily and efficiently streaming dynamic, asynchronous data with JavaScript. This will naturally lead us into our next chapter on _Streams_. 

<InfoBox hint>
There are a few more chapters like this later, too. I know it might be frustrating to not dive headfirst into the React codebase, but a thorough knowledge of these concepts is key to understanding how _RSC_'s actually work. I've worked really hard to put together a bunch of demos that make it all very clear. I will also be establishing some basic _RSC_ knowledge throughout the chapter which I will refer to throughout the series. 

If you truly think that you understand this stuff well enough already and you just want to get to the gritty details, you can [just click here to skip to the fourth chapter](./4-flight-request). I get it! Otherwise, let's explore the history of the web and the internal mechanisms of JavaScript runtimes to start understanding how React deftly conducts an orchestra of modern web APIs to make server components work. It all starts with events.
</InfoBox>

## Asynchronous JavaScript

For the first few of years, almost every web page was completely static. [Tim Berners-Lee](https://home.cern/science/computing/birth-web/short-history-web) created [the first website](https://thehistoryoftheweb.com/the-first-website-in-the-united-states-was-made-for-physicists/) in late 1991, but it wasn't the next year that [a browser called Viola introduced forms](https://www.webdesignmuseum.org/web-design-history/violawww-1992). Viola became [well regarded](https://arstechnica.com/information-technology/2019/05/before-netscape-forgotten-web-browsers-of-the-early-1990s/2/) for this and other features, but it was pretty rare for a website to do very much with this new capability. 

You could dynamically respond to the user's request when they filled out the form, but this required an entire round-trip back and forth from the server. This could be frustratingly slow in the era of the dial-up modem. This was because it required loading in an entirely new document while discarding everything on the current page. 

Usually, this was facilitated by a [Common Gateway Interface](https://webdevelopmenthistory.com/1993-cgi-scripts-and-early-server-side-web-programming/). This was a specification for designing dynamic web servers that was developed at the NCSA. The [National Center for Supercomputing Applications](https://en.wikipedia.org/wiki/National_Center_for_Supercomputing_Applications) was responsible for many of the early innovations on the web.

Chief among these was [a web browser called Mosaic](https://en.wikipedia.org/wiki/Mosaic_(web_browser)) that was released in 1993. Created by two developers named Marc Andreessen and Eric Bina while working at the NCSA, Mosaic distinguished itself by being able to do little things like [show images in the same window](https://thehistoryoftheweb.com/the-origin-of-the-img-tag/) as the rest of the document. This might sound like nothing today, but you have to remember that this was completely revolutionary at the time.

Andreessen and Bina soon left the NCSA to found their own company with a man named James H. Clark. Calling themselves Netscape, they quickly released a new browser named Navigator which was [even more revolutionary](https://www.popularmechanics.com/culture/web/a27033147/netscape-navigator-history/). As this was their main product, most people just called the browser Netscape. The first version became [extremely popular](https://webdevelopmenthistory.com/1996-netscape-lays-the-groundwork-for-web-applications/) as it introduced things like tables and background images. 

At that point, it was expected that these kinds of presentational aspects would emerge. The way to add more dynamicism to a web page than a form could offer was much less obvious however. So, the [release of Netscape 2.0](http://sunsite.uakom.sk/sunworldonline/swol-10-1995/swol-10-netscape.html) truly changed the web forever when it introduced the world to JavaScript.

### Events

Asynchronous code has [always been a part of JavaScript](https://webdevelopmenthistory.com/1995-the-birth-of-javascript/). This is most evident when adding an event listener to a DOM element. You're saying that you want some code to run eventually, but only after the user initiates it by doing something in the browser.

JavaScript's event system was [greatly inspired](https://www.youtube.com/watch?v=QgwSUtYSUqA&t=1035s) by an application development kit from Apple called [HyperCard](https://en.wikipedia.org/wiki/HyperCard). HyperCard was included for free in all Macintosh computers. It allowed programmers to easily respond to ["System Messages"](https://cancel.fm/stuff/share/HyperCard_Script_Language_Guide_1.pdf) like when the user was hovering their mouse over something. 

If you look at the initial [release notes](https://web.archive.org/web/19970614001401/http://home.netscape.com/eng/mozilla/2.0/relnotes/mac-2.0b2.html) for the beta version in which JavaScript was released to the world, this is how it was described:

> A programmable API that allows cross-platform scripting of events, objects, and actions. It allows the page designer to access events such as startups, exits, and user mouse clicks.

Despite the [original JavaScript guide released with Netscape 2.0](https://web.archive.org/web/19970613234917/http://home.netscape.com/eng/mozilla/2.0/handbook/javascript/index.html) having [a whole section](https://web.archive.org/web/19970617232705fw_/http://home.netscape.com/eng/mozilla/2.0/handbook/javascript/ref_m-q.html#onBlur_event) dedicated to event handlers, events were not a part of any actual spec until [DOM level 2](https://www.w3.org/TR/DOM-Level-2-HTML/). This was in the year 2000-- around five years after the first version of JavaScript was released. The spec codified familiar API's like `addEventListener`, but it was a bit of an uphill battle. 

### Internet Explorer

It's hard to understate the effect that Netscape had on the early web. Microsoft ignored them at first, but it was impossible to do this for long. After releasing an internal memo called ["The Internet Tidal Wave"](https://www.wired.com/2010/05/0526bill-gates-internet-memo/), Microsoft [attempted to purchase Netscape in 1994](https://topenddevs.com/podcasts/javascript-jabber/episodes/124-jsj-the-origin-of-javascript-with-brendan-eich). After being rebuffed, they pivoted and [courted a competitor named Spyglass](https://www.nytimes.com/1998/03/02/business/spyglass-a-pioneer-learns-hard-lessons-about-microsoft.html) who were the owners of the Mosaic license. 

While this started as a licensing agreement, Microsoft soon took the codebase and created Internet Explorer. They completely upset the market by releasing it for free-- abusing as [many](https://en.wikipedia.org/wiki/United_States_v._Microsoft_Corp.) [legal](https://www.theringer.com/tech/2018/5/18/17362452/microsoft-antitrust-lawsuit-netscape-internet-explorer-20-years) [grey](https://ericsink.com/Browser_Wars.html) [areas](https://archive.nytimes.com/www.nytimes.com/library/tech/98/05/biztech/articles/25microsoft-java.html) as possible at the time. No one had even considered that a browser could be free-- especially all the people paying for something almost identical.

This marked the beginning of the [browser wars](https://en.wikipedia.org/wiki/Browser_wars) which was really more like a massacre. To avert the "monster truck in their rear-view mirror", Netscape made the audacious yet necessary move to [open-source their software suite in February 1998](https://web.archive.org/web/19980706003741/http://www.netscape.com/newsref/pr/newsrelease577.html). The foundation created to steward this codebase was named Mozilla.

Internet Explorer quickly became the most popular browser by far. This was not surprising as it was not only free and [more performant than Netscape](https://web.archive.org/web/20200307173732/http://www.wirfs-brock.com/allen/files/jshistory/JScriptInterview.mp3), but it was also [incredibly innovative at first](https://humanwhocodes.com/blog/2012/08/22/the-innovations-of-internet-explorer/). It blazed the trail for many exciting features including [the first CSS integration](https://en.wikipedia.org/wiki/CSS). 

Of course, it also needed a dynamic scripting language. The original plan was to implement Visual Basic in Internet Explorer, but the engineers thought that would take two years. Also, they knew that they would have to support all the same websites as Netscape to be able to supplant it. 

So, Microsoft created [JScript](https://en.wikipedia.org/wiki/JScript) in 1996 by reverse engineering JavaScript. Eventually, they even got a subset of Visual Basic called Visual Basic Script (VBS) to run in its interpreter. The replication of JavaScript was near exact in many ways, but there were some key differences when it came to user interaction.

Unfortunately, because there was no standard, Internet Explorer chose to use [a different event system entirely](https://docstore.mik.ua/orelly/webprog/jscript/ch19_03.htm). If you've ever been confused by the concepts of event [bubbling and capturing](https://javascript.info/bubbling-and-capturing), you have this period of relative chaos to blame. Thankfully, over a decade later, _IE_ [eventually jumped on board](https://www.howtocreate.co.uk/jshistory.html) with the _DOM Level 2_ event model by IE9 in 2007. Developers were still forced to do checks for `window.event` for years afterwards to ensure backwards compatibility.

### `setTimeout` and `setInterval`

So, that covers the introduction of scripted, programmatic responses to user interaction in the browser. But, you don't always want to rely on the behavior of the user to get things going. What about something that happens over a span of time independent of outside stimulus-- like [a cool text ticker](https://web.archive.org/web/19990203103422fw_/http://planetx.bloomu.edu/~mpscho/jsarchive/ticker.html)!

In my research for this article, I was really struggling to find any definitive information about the introduction of `setTimeout`. These objects that have been included since Netscape 2.0 are sometimes referred to as [DOM level 0](https://www.quirksmode.org/js/dom0.html). Shortly before I found that Netscape 2.0 JavaScript guide, I got frustrated and decided to just ask the man himself. [According to Brendan Eich](https://x.com/BrendanEich/status/1705273184109596726), setTimeout was created in 1995.

Considering that JavaScript was released in December of that year, it's pretty safe to say that it's been there since the very beginning. `setInterval` joined it soon afterwards in 1996. `setTimeout` and `setInterval` both take two arguments: a function and an amount of time.

`setTimeout` will run the function once after that amount of time whereas `setInterval` runs it repeatedly at whatever rate is specified by that second argument. This is only possible because JavaScript has ["First-Class Functions"](https://en.wikipedia.org/wiki/First-class_function). This means that you can pass them as arguments to other functions and assign them to variables so they can be called at a later point. Thus, these functions are appropriately termed _callbacks_.

### Callbacks

The idea is simple. You construct a function that takes some parameters and uses them to do stuff. Then, you pass it as an argument to another function or as an HTML event attribute to define what happens when a certain condition is met. Instead of running the function immediately, the browser holds it in memory and waits to _call it back_ when the event fires, the timeout runs out, the download completes, etc.

This pattern dominated the JavaScript scene for the first twenty years. It's a natural fit for browser code, and it still works well for many situations. Before [the birth of AJAX](../client-side-routing/2-a-brief-history-of-client-side-routing#the-birth-of-ajax), it was pretty rare for a website to do much complex interaction with JavaScript.

So, this was enough for client-side JS for a long time. And, after Ryan Dahl and company created Node, it was only natural for them to build it with these concepts in mind. As we'll discuss in the next chapter, Node created the custom class `EventEmitter` for things like streams specifically so that they could be represented within an event-driven architecture. 

While you could still easily end up in [callback hell](http://callbackhell.com/), using something like jQuery paved over many of the hurdles. One of the worst aspects is error-handling. If you want to deal with any exceptions that may occur, you need to pass a special callback through as an additional argument to each level of this [pyramid of doom](https://en.wikipedia.org/wiki/Pyramid_of_doom_(programming)). But, this [continuation passing style](https://www.youtube.com/watch?v=V2Q13hzTGmA) was the only way to avoid blocking, synchronous code.

### Synchronous Code

From the very beginning, the way that browsers have [interpreted documents](https://www.oreilly.com/library/view/head-first-html/9781449324469/ch01.html#:~:text=When%20the%20browser%20reads%20your,and%20meaning%20of%20your%20text.) has been [rather complex](https://web.dev/howbrowserswork/#tree-construction-algorithm). This is partially due to HTML's forgiving nature as browsers will still try to show you something even if the developer made a mistake. In this process, one thing is assured: the browser will parse it from the top-down to build the DOM.

If it gets to any script tags, it will pause everything else until it finishes executing what it finds inside. This ["run-to-completion"](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Event_loop#run-to-completion) model is synchronous in nature because the browser processes each line of code sequentially-- one after the other. This makes JavaScript extremely predictable, but it can lead to a bad user experience if one line of code takes a long time.

This is because the browser only uses [a single thread](https://developer.mozilla.org/en-US/docs/Glossary/Main_thread) to process all the JavaScript on the page. When we're talking about computers, [a thread](https://en.wikipedia.org/wiki/Thread_(computing)) just represents the smallest thing that a computer can do at once. The main thread is what is actually running the code that you write [among many other things](https://www.youtube.com/watch?v=7Rrv9qFMWNM&start=300). Critically, it's also the thread that is used to build the DOM and render the page.

So, you have to be careful about [how you load and run your JavaScript](https://developer.mozilla.org/en-US/docs/Web/Performance/How_browsers_work#interactivity). Although modern computers have access to [multiple cores](https://en.wikipedia.org/wiki/Multi-core_processor) and [multithreading](https://en.wikipedia.org/wiki/Simultaneous_multithreading) exists, the browser is doing much more than just running your JavaScript. And, your computer is doing much more than just running the browser. So, when one function takes a long time, it is said to be [blocking the main thread](https://developer.chrome.com/blog/inside-browser-part3/#javascript-can-block-the-parsing). As long as that function is running, the browser cannot do anything else.

This is why _callbacks_ and elaborate `setTimeout` chains were so dominant in JavaScript. The internet is asynchronous in nature. It takes time to download requests. So, you had to bend over backwards to try to make all of this synchronous code work in an asynchronous world. An official solution was inevitable. We'll get to that soon, but in order to understand promises, it's essential to understand the event loop itself.

<IFrame src="https://stackblitz.com/edit/primitive-async?ctl=1&embed=1&view=preview" />

## The Event loop

This will just be an introduction. Before we can understand how promises fit into this structure, we need to understand why the event loop even exists. If all JavaScript code was synchronous, there would be no need for it.

### Web API's

Despite JavaScript's single-threaded nature, browsers need to be able to handle things like `setTimeout` or events that aren't processed immediately. This might surprise you, but _Web API_'s like `setTimeout` are not actually a part of the core JavaScript specification. Despite the fact that it is so essential to the language that it has been there since the very beginning, the earliest discussion I could find about [standardizing `setTimeout` was in 2005](https://brendaneich.com/2005/06/javascript-1-2-and-in-between/#comment-289). 

Eventually, [it was added to the HTML standard in 2011](https://www.w3.org/TR/2011/WD-html5-20110525/timers.html). It's still rather barebones however, and the timers are an implementation detail left up to the individual browsers. Although [it was discussed in 2010](https://esdiscuss.org/topic/bringing-settimeout-to-ecmascript), it is still not included in the EcmaScript Standard. 

This is what it means when we say something is a [_Web API_](https://developer.mozilla.org/en-US/docs/Web/API). It's something extra that each runtime adds to the JavaScript engine individually. For instance, if you download just the v8 engine and you try to run a function with a `setTimeout`, [you will get a `ReferenceError`](https://stackoverflow.com/questions/12335222/settimeout-and-v8).

Sometimes, these _Web APIs_ are referred to as the [Browser Object Model](https://javascript.info/browser-environment#bom-browser-object-model). This was because it was originally just a few objects like `navigator` that provided information about the execution environment. But, with the spread of these standards to server-side JavaScript, this term is slightly outdated.

The important thing to understand is [this is what separates a JavaScript engine like v8 from a JavaScript runtime like Node](https://www.youtube.com/watch?v=8aGhZQkoFbQ). The engine only implements the core JavaScript specification which is mostly logic and syntax. The runtime gives it an environment where that code can be executed and ways to interact with the outside world.

Generally, these _Web APIs_ will operate on separate threads. This is what gives JavaScript the ability to operate concurrently, but it's important to note that everything still needs to be processed sequentially on the main thread-- at least until Web Workers emerge. So, the runtime needs a way to keep track of all of these asynchronous tasks and schedule them to be processed in the correct order. This is where the event loop comes in.

### Memory: Stack and Heap

Before actually executing any code, the JavaScript runtime will first go through the script and [parse it](https://www.nearform.com/blog/what-is-an-abstract-syntax-tree/) into an [abstract syntax tree](https://astexplorer.net/). It will create a new [lexical environment](https://github.com/getify/You-Dont-Know-JS/blob/2nd-ed/scope-closures/ch1.md) for each code block that it finds. For each of these lexical environments, the runtime will create an [environment record](https://blog.openreplay.com/explaining-javascript-s-execution-context-and-stack/) which will contain any variables declared within their scope. Every one of these environments is defined within a [code realm](http://dmitrysoshnikov.com/ecmascript/javascript-the-core-2nd-edition/#realm) which provides a global [_execution context_](https://www.atatus.com/blog/how-does-javascript-works/#execution-contexts-and-execution-stack). 

That's a lot of big words to describe what we know as [hoisting in JavaScript](https://stackoverflow.com/questions/45620041/how-does-hoisting-work-if-javascript-is-an-interpreted-language). In layman's terms, this is how [the runtime keeps track of each variable and function](https://www.yash.works/hoisting-in-javascript) that it finds so it can use them later if appropriate. The runtime stores all of this in [a memory heap](https://v8.dev/blog/pointer-compression#value-tagging-in-v8) which is [a flexible data structure](https://deepu.tech/memory-management-in-v8/) that can grow and shrink as needed. 

However, the JavaScript runtime also needs a way to keep track of the order in which any functions are invoked. Each runtime keeps a fixed amount of memory where it stores a data structure known as the [call stack](https://developer.mozilla.org/en-US/docs/Glossary/Call_stack) for this purpose. This facilitates a scheduling mechanism called [the _event loop_](https://felixgerschau.com/javascript-event-loop-call-stack/).

### The Call Stack

After building the global _execution context_, the runtime begins to actually process the script [line-by-line](https://www.youtube.com/watch?v=Z6a1cLyq7Ac&list=PLWrQZnG8l0E4kd1T_nyuVoxQUaYEWFgcD&index=1). As it interprets the code, the JavaScript runtime builds [a _call stack_](https://en.wikipedia.org/wiki/Call_stack) of all the function invocations that it finds. This is what allows it to keep track of where it is in the code. When it encounters the pair of parentheses necessary to call a function, the runtime pushes the function being invoked onto the _call stack_ and starts executing it. 

The _call stack_ is _LIFO (Last In, First Out)_. Moving from top to bottom, each function is popped off the stack as it finishes executing. But, if a function calls a bunch more synchronous functions, all of those need to run before the engine can move on to the next line of code.

Each function that gets invoked gets turned into something called [a _stack frame_](http://rabbit.eng.miami.edu/class/519/frames.html). This contains everything necessary for the function to run such as the arguments, local variables, and the current line number. The runtime creates a variable environment where anything defined in the function is stored. All together, this is known as [that function's _execution context_](https://cabulous.medium.com/javascript-execution-context-part-1-from-compiling-to-execution-84c11c0660f5). We'll cover execution context in greater detail in [chapter 7](./7-proxies-and-context).

As the JavaScript engine is working its way through the _call stack_, it is also building a _task queue_ for anything asynchronous. Anything that doesn't resolve immediately like network requests, `setTimeout` callbacks, or any other call to a _Web API_ will be placed into this queue. The runtime executes these on separate threads so that they don't interfere with the single-threaded _call stack_.

### The Task Queue

As each frame is processed and the _call stack_ unwinds, the _task queue_ is growing. Generally, this is done by giving the _Web API_ a callback that describes what you need to happen later. So, the _task queue_ is also sometimes known as the _callback queue_.

As each _Web API_ finishes whatever it was doing, it places the callback it was given into the _task queue_. When we reach the end of the script, the runtime will check the _task queue_ to see if anything's there. If there is, each callback is moved onto the _call stack_ in sequential order starting with the oldest one.

In contrast to the _call stack_, the _task queue_ is _FIFO (First In, First Out)_. So, everything placed in the queue will progressively run in the order it is added. If there are multiple items in the queue, and the first task adds more tasks to the queue, those have to wait for everything else in the queue to finish before they can be processed. 

None of that can happen until the _call stack_ created by the first task is fully unwound. So, if its callback invokes several more synchronous functions, each of those must be processed and the _call stack_ must be drained again before the runtime can move on to the next item in the _task queue_. This is why it's so important to avoid blocking the main thread, because the next item in the _task queue_ might be from the user trying to interact with the web page.

So, the _event loop_ is what allows JavaScript code to be non-blocking when the engine itself is synchronous and single-threaded. It gives JavaSript runtimes a stable, predictable way to process asynchronous code. This is part of what made it attractive as a server-side language.

The event loop ensures that each HTTP request can be processed in a predictable, efficient manner-- just like clicking a button. Although Node has become immensely popular, JavaScript's road to server-side prominence was a long and winding one. This is despite the fact that there were plans for it from the very beginning.

## Server-Side JavaScript

Node may have been what made the world take JavaScript seriously as a server-side language, but it wasn't even close to the first use of JavaScript on the server. In fact, the very first time Netscape even hinted at JavaScript was in their press release for [a server framework called LiveWire](https://web.archive.org/web/19981202062552/http://home.netscape.com/newsref/pr/newsrelease41.html). It briefly described a "Java-based scripting language to enable developers to create and execute Live Objects, or interactive multimedia content, within their applications." 

In its earliest days around May of 1995, [this was codenamed Mocha](https://brendaneich.com/2008/04/popularity/). Later, it was [briefly named LiveScript](https://www.oreilly.com/library/view/node-up-and/9781449332235/pr03.html) to match the server framework, but this was all [changing very fast](https://groups.google.com/g/comp.lang.javascript/c/CqDXNTWNZPA/m/eTo7NCWHNyAJ). By the time of the [very first press release](https://web.archive.org/web/20070916144913/https://wp.netscape.com/newsref/pr/newsrelease67.html) specifically about it, the scripting language had been given its final name.

> JavaScript is an easy-to-use object scripting language designed for creating live online applications that link together objects and resources on **both clients and servers**. While Java is used by programmers to create new objects and applets, JavaScript is designed for use by HTML page authors and enterprise application developers to dynamically script the behavior of objects running on **either the client or the server**.

Java was brand new and extremely popular at the time, and Netscape had acquired the copyright because they wanted to incorporate it into their browser. In the end, the connection between JS and Java has always been tenuous at best. Brendan Eich went as far as to call this a [marketing scam](https://www.youtube.com/watch?v=WqMbzVWIAjY&start=195).

It can be argued that Java was never meant to be a client-side language. It's a compiled language, and it did not have first-class functions at the time. So, NetScape knew they needed a light-weight scripting language for handling events directly in HTML documents. Marc Andreessen [later said this about why he wanted to create JavaScript](https://web.archive.org/web/20051113013615/https://wp.netscape.com/comprod/columns/techvision/innovators_be.html):

> What people wanted back then (and still want) is the ability to go one step beyond HTML and add a little bit of code that makes a web page dynamic... things that HTML cannot express. That's really where you need a programming language, but something simpler than Java or C++.

This was why Netscape hired Brendan Eich to create what eventually became JavaScript. For the first year, he was the only engineer working on it. He later said that Andreessen told him the language needed to be ["right there in the page"](https://www.youtube.com/watch?v=krB0enBeSiE&start=2220). This idea to write the code directly in the middle of the mark-up was radically innovative. 

[Netscape Livewire exploited this](http://web.archive.org/web/19961115040956/http://developer.netscape.com/library/documentation/livewire/index.html). Livewire used a special `<SERVER>` tag within which one could do any server-side processing necessary like queries to databases. For the first few months, Brendan Eich actually worked on the Netscape server team.

### LiveWire

While it was marketed aggressively initially, it seems like Netscape Livewire ended up as a bit of an afterthought. According to Brendan Eich, it got ["overwhelmed in the Java onslaught"](https://brendaneich.com/2011/01/harmony-of-my-dreams/#comment-826). It was basically [a fairly limited HTML pre-processor](https://dev.to/macargnelutti/server-side-javascript-a-decade-before-node-js-with-netscape-livewire-l72). 

While some aspects of working with Livewire are reminiscent of modern server-side JavaScript, others are drastically different. It [required compilation](https://www.leins.net/gespiegeltes/javascript-11-developers-guide.html) into a single, propietary `.web` file for the entire server. This allowed it to have [a native multi-threaded execution model](https://stackoverflow.com/questions/18350910/netscape-enterprise-server-and-server-side-javascript-ssjs-vs-node-js), but it lacked asynchronous features so one had to be careful not to block any of these threads. 

It had a stateful request caching system, but this was [met with mixed reviews](https://philip.greenspun.com/wtr/livewire.html). For the most part, the options for [passing state back and forth between client and server](https://docs.oracle.com/cd/E19957-01/816-6411-10/sessmgmt.htm#1036896) were pretty limited, but somewhat familiar to what we have today. Things like cookies and url encoding were already well established.

Later, the [LiveConnect feature](https://docs.oracle.com/cd/E19957-01/816-6411-10/lc.htm) actually enabled developers to share objects between JavaScript and Java-- although [this had some security issues and never really caught on](http://www.white-mountain.org/jamie/software/livewire-sucks.shtml). Netscape encapsulated this grand vision of an inter-connected, cross-platform development environment into a holistic brand called [Netscape One](http://home.netscape.com/comprod/one/white_paper.html).

### The Early 2000's

In November of 1998, Netscape was [purchased by America Online](https://money.cnn.com/1998/11/24/technology/aol/) for the absurd price of $4.2 billion dollars. Despite spending this much money on the acquisition and [some lofty aspirations](https://web.archive.org/web/19990508123753/http%3A//home.netscape.com/columns/mainthing/merger.html), nothing much every came from this deal. After five years and another merger, [AOL Time Warner sold what was left of Netscape](https://www.forbes.com/2003/05/30/cx_da_0530topnews.html?sh=24be73171176) for $750 million dollars to Microsoft.

By 1999, Internet Explorer was the dominant browser, and it was still [using the same rendering engine](https://en.wikipedia.org/wiki/Trident_(software)) that it had been using since 1997. Although alternatives like [Opera](https://en.wikipedia.org/wiki/Opera_(web_browser)) and [Konqueror](https://en.wikipedia.org/wiki/Konqueror) continued to be maintained, they were [the minority by far](https://en.wikipedia.org/wiki/Browser_wars#/media/File:Layout_engine_usage_share-2009-01-07.svg).

While Netscape's server offerings continued to exist through the [iPlanet alliance with Sun](https://en.wikipedia.org/wiki/IPlanet), it was rarely used. There were some other server-side JavaScript implementations in the years afterwards. [Rhino](https://en.wikipedia.org/wiki/Rhino_(JavaScript_engine)) went so far as to fully implement a JavaScript engine in Java which helped some embrace its use on the server-side.

[ASP](https://en.wikipedia.org/wiki/Active_Server_Pages) was released by Microsoft at the end of 1996, and it allowed developers to use JScript & VBS on the server. Again, relatively few developers chose to use this feature. Later versions of their server-side software highlighted lower-level languages like C#, but the [Web Forms feature](https://www.dotnetcurry.com/aspnet/1492/aspnet-history-part-1) released with the .NET framework in the early 2000s was embraced by some.

Many in the community were [still convinced](https://www.slideshare.net/alexandre_morgaut/state-of-the-art-server-side-java-script-webworkerscamp-9406069) that JavaScript had a place on the server. This cross-platform ability is mentioned explicitly in the overview of [the very first EcmaScript Standard](https://www.ecma-international.org/wp-content/uploads/ECMA-262_1st_edition_june_1997.pdf) in June 1997. This was even before the concept of an "event" was formalized in Dom Level 2. 

> ECMAScript was originally designed to be a Web scripting language, providing a mechanism to enliven Web pages in browsers and **to perform server computation** as part of a Web-based client-server architecture. ECMAScript can provide core scripting capabilities for **a variety of host environments**, and therefore the core scripting language is specified in this document apart from any particular host environment.

### TraceMonkey

From the very beginning, JavaScript engines were relatively simple and not very performant. Brendan Eich famously [built the first one in ten days](https://brendaneich.com/2011/06/new-javascript-engine-module-owner/). Originally, they just interpreted scripts line-by-line into [bytecode](https://en.wikipedia.org/wiki/Bytecode). In fall 1996, realizing that it was inherently flawed, he rewrote the original engine over another two-week period. The engine was still being called Mocha, so Eich decided to rename it to SpiderMonkey at this point. A version of this engine still runs Firefox today, but the way it works is very different.

As [some predicted at the time](https://www.jwz.org/gruntle/aol.html), the sale of Netscape to AOL in 2003 actually turned out to be a great thing for the Mozilla project. Blessed with [a parting gift of $2 million dollars](https://blog.mozilla.org/press/2003/07/mozilla-org-announces-launch-of-the-mozilla-foundation-to-lead-open-source-browser-efforts/), the Mozilla Foundation was formed which completely separated them from any corporate interests. Now, they were able to [fully focus on the open web](https://www.mozilla.org/en-US/about/history/). 

This led to the release of [Firefox 1.0 in 2004](https://blog.mozilla.org/press/2004/11/mozilla-foundation-releases-the-highly-anticipated-mozilla-firefox-1-0-web-browser/). Firefox was incredibly innovative for its time. The first edition popularized things like a built-in pop-up blocker, tabs, and browser add-ons.

[Firefox 3.5 introduced TraceMonkey](https://brendaneich.com/2008/08/tracemonkey-javascript-lightspeed/) in August 2008 which was the first _Just-In-Time (JIT)_ Compiler for JavaScript. Instead of interpreting it into bytecode the same way every time, TraceMonkey observed the code as it was being executed and watched for the most expensive parts. These "hot paths" were compiled into more performant [machine code](https://en.wikipedia.org/wiki/Machine_code). 

The Mozilla team reckoned that the easiest thing to optimize was loops. It seems like [TraceMonkey was pretty limited](https://www.cs.cornell.edu/courses/cs6120/2020fa/blog/tracemonkey/) in its capabilities beyond this. However, this may be viewing it with a modern lens as TraceMonkey was considered to be extremely innovative at the time.

### V8

Just one month later, Google released Chrome along with its new JavaScript engine, v8. Instead of attempting to use a tracer to help optimize the interpreter after finding the most expensive parts, [v8 initially went even further and removed the interpreter entirely](https://web.archive.org/web/20080911072531/http://code.google.com/apis/v8/design.html). By pre-compiling the entirety of the code at runtime, this allowed for [more efficient memory management](https://www.youtube.com/watch?v=FrufJFBSoQY) through inline caching, hidden classes, and better garbage collection. 

Google Chrome was announced to great acclaim. Along with pioneering [new security features and tabs](https://www.youtube.com/watch?v=JGmO7Oximw8), it was also released with [a controversial set of benchmarks](https://web.archive.org/web/20080911072531/http://code.google.com/apis/v8/benchmarks.html). Google [claimed it was ten times faster](https://docs.google.com/presentation/d/1HgDDXBYqCJNasBKBDf9szap1j4q4wnSHhOYpaNy5mHU/edit#slide=id.g17d335048f_1_1903) than the competition. [Third-party benchmarks](https://johnresig.com/blog/javascript-performance-rundown/) were more inconclusive, and Apple soon released their own JIT compiler which was [extremely competitive](https://webkit.org/blog/189/announcing-squirrelfish/) as well. 

This [wave of increased performance](https://arstechnica.com/information-technology/2008/10/extreme-javascript-performance/) changed everything. Within two years, Firefox had incorporated a [new hybrid technique](https://hacks.mozilla.org/2010/03/improving-javascript-performance-with-jagermonkey/) that combined full-method compilation with their tracing engine. v8 soon followed suit in December 2010 with a new infrastructure called [Crankshaft](https://blog.chromium.org/2010/12/new-crankshaft-for-v8.html). Now, every major browser vendor incorporates [a blend of these strategies](https://mathiasbynens.be/notes/shapes-ics) to fully optimize the code.

### Node

JavaScript's naturally event-driven design was part of what drew Ryan Dahl to use it to build servers. After years of being frustrated by the blocking nature of Ruby servers, [he was blown away](https://www.youtube.com/watch?v=SAc0vQCC6UQ) by the performance made possible by Google's recently released v8 engine. The initial, stated goal of the Node.js project was "to provide a [purely evented, non-blocking infrastructure](https://www.youtube.com/watch?v=ztspvPYybIY) to script highly concurrent programs." JavaScript's origins in the browser make it perfect for this. 

I have [already discussed](./2-chunks) the fact that Node has built many of its core internals around the `EventEmitter` API. Every stream is an `EventEmitter` and this powers all file & network I/O. Events and callbacks are at the very heart of Node. All the core API's are designed so that one can just keep passing things through functions to help avoid blocking the call stack as much as possible.

Node's event loop needed to be [a bit more complex](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick) than the browser's. Because there are even more asynchronous considerations in Node, like writing files to the disk, there are six distinct phases in its event loop. Additionally, they introduced two new concepts: the _next tick queue_ and `setImmediate`.

### Next Tick Queue

The _next tick queue_ emerged as a way to ensure that certain callbacks are processed before the next pass through the event loop. Between each of the six phases, Node checks the _next tick queue_ to see if there is anything there. Everything in the queue is processed before moving on to the next phase of the event loop. To place something there, all you need to do is call a function called `process.nextTick()` and pass it a callback.

This feeds into Node's mantra of [non-blocking code](https://nodejs.org/en/docs/guides/blocking-vs-non-blocking). It allows developers to carefully orchestrate the order in which things happen. This is especially useful for things like error handling. If anything needs to be processed urgently, but it also needs to wait on things to be set up by the synchronous code, it can be placed in the _next tick queue_. For something that can wait until near the end of the event loop, there is `setImmediate`.

### setImmediate

`setImmediate` is extremely similar to `setTimeout` with a delay of `0`, but it's not exactly the same. Technically, they exist in two different phases of the event loop. `setTimeout` callbacks are processed in the _timers_ phase whereas `setImmediate` callbacks are processed in the _check_ phase. Depending on [a variety of factors](https://nodejs.org/en/docs/guides/event-loop-timers-and-nexttick/#setimmediate-vs-settimeout), this can make a difference in the order in which they are processed.

`setImmediate` was [originally intended to be a web standard](https://jatindersmann.com/2012/08/07/ieblog-web-performance-apis-rapidly-become-w3c-candidate-recommendations/), but this never properly materialized. At this point, it is only supported by Node and Internet Explorer. But, it can be [really handy for certain situations](https://exploringjs.com/nodejs-shell-scripting/ch_nodejs-overview.html#next-tick-tasks-and-microtasks-vs.-normal-tasks).

### Proto-Promises

It might surprise you to know that Node contained [something called a _promise_](https://github.com/nodejs/node-v0.x-archive/blob/490cac0d7e9b455de74eb6038e555a60a2fafe13/src/node.js#L196) in some of its very first versions. They even [came up in Ryan Dahl's initial announcement](https://groups.google.com/g/commonjs/c/tFO0rDFYAmg/m/0kDHteaMRB8J) to the CommonJS group. At [the talk at JSConf EU 2009](https://www.youtube.com/watch?v=EeYvFl7li9E) where he announced Node to the rest of the world, Dahl spent some time to define them. He included a slide that declared that "A Promise is an `EventEmitter` which emits either a success or an error event (but not both)".

Eventually, these proto-promises were [removed in early 2010](https://groups.google.com/g/nodejs/c/jaufClrXU9U/m/ov5WHIk7SAwJ) as there were some [flaws in the API](https://groups.google.com/g/nodejs/c/sWE0Oa80iNg/m/-n7xPyOdGd8J) and Ryan Dahl eventually decided to [defer to user libraries](https://groups.google.com/g/nodejs/c/RvNoQtoWyZA/m/a8Hu83Ewb0IJ) for any future promise implementations. He later listed this as [one of his greatest regrets when it came to Node](https://www.youtube.com/watch?v=M3BM9TB-8yA) and it [caused a bit of frustration at the time](https://www.sequoiacap.com/article/deno-spotlight/).

<IFrame src="https://stackblitz.com/edit/node-event-loop?ctl=1&embed=1&view=preview" />

## Promises/A+ and Thenables

This goes to show how long people have been considering something like promises to be a useful tool when working with asynchronous code. In fact, the concept goes [back much further than that](https://samsaccone.com/posts/history-of-promises.html). You can trace it to the conception of a "thunk" in [ALGOL languages](https://en.wikipedia.org/wiki/ALGOL_60), or the idea of [a future](https://en.wikipedia.org/wiki/Futures_and_promises). Basically, it's just a way to represent a value that will be available at some point in the future-- but not right now.

The first attempt at properly classifying promises in JavaScript was the [Promises/A specification](https://wiki.commonjs.org/wiki/Promises/A) from CommonJS, but there were many variations. I already mentioned jQuery which has included a [slightly-less-functional version of promises](https://api.jquery.com/Types/#Deferred) since [2011](https://blog.jquery.com/2011/01/31/jquery-15-released/). In fact, something similar to its concept of a `Deferred` object is finally making its way into JavaScript with the [`Promise.withResolvers` proposal](https://github.com/tc39/proposal-promise-with-resolvers) despite some considering it [an anti-pattern](https://github.com/petkaantonov/bluebird/wiki/Promise-anti-patterns#the-deferred-anti-pattern). 

### Promises 101

[To quote MDN](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise), "A Promise is an object representing the eventual completion or failure of an asynchronous operation... [it's] a proxy for a value not necessarily known when the promise is created." 

A promise is always in one of three states: _pending_, _fulfilled_, or _rejected_. Whether a promise is _fulfilled_ or _rejected_, it becomes _settled_ once it is no longer _pending_. Critically, this can only happen once as you _resolve_ the promise. Until _then_, the promise is _unresolved_.

### Friendship 101

Let's bring it back home with another fun metaphor. Don't worry, I'm not very inventive. Just think about making a promise to a friend. You're basically saying, "I will definitely do that one thing-- just not right now." Outside the _context_ of that promise, everything else you're doing at that moment is irrelevant. 

What matters is what happens next. Until **then**, that promise (and your friendship) is **pending**. _Then_, you will see if you can **fulfill** that commitment. This will show the **value** of that promise to you both. Otherwise, you will have to **reject** your friend. They will expect a good **reason**.

You can **resolve** this promise and find the **value** right away, or you can **resolve** it with another promise and pass the **value** along. If you can't complete your commitment to your friend immediately, this is like saying that you need to do something else first. _Then_, the first promise if **fulfilled**, and the new promise is **pending**.

This is because you can't keep passing them the same promise forever. They're going to get tired of your excuses, so everything will have to get **settled** eventually. That can only happen once all the promises you made to your friend have been fully **resolved**.

Any errors that you make when handling these promises will be the same as if you **rejected** your friend. You can make a single generic **reason** or you can try to handle each error individually. If you don't **catch** one of these errors, it could wreck your whole friendship. Your friendship is strong enough that they will accept the generic **reason**, but you respect your friend. So, you usually want to **catch** each error individually.

In the end, each promise must be either **fulfilled** or **rejected**, and this can only happen once. Anything else would have to be another, separate promise. You can't go back and change the past. To fix the friendship, you can only make new promises-- perhaps even several in a row.

### `.then()`

The most important thing to understand about promises is that they always possess a `.then()` method. This method takes two arguments which are both functions-- one for the fulfilled case and one for the rejected case. Either way, it returns an entirely new, unresolved promise. Because of this, they can be chained one after the other-- much like how I used the word 'then' to chain multiple clauses together in the previous section.

Like I said earlier, [several libraries implemented similar functionality beforehand](https://web.dev/promises/#promises-arrive-in-javascript). Thus, there are many objects that exist with a `.then()` method that are not technically promises. Generally, while these may have many similarities to actual promises, they may not have all of the same properties. So, they are often called [_thenables_](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Promise#thenables) to mark the distinction. Native EcmaScript `Promise` objects were designed to work natively with most _thenables_.

### Standardization

By 2012, there was a proliferation of [libraries intended to help developers with asynchronous code](https://web.archive.org/web/20130724052629/https://github.com/joyent/node/wiki/modules#wiki-async-flow). This was a clear indication that there was a need for a standard. Many in the community advocated for something stricter than the _Promises/A_ standard. So, [the _Promises/A+_ specification](https://promisesaplus.com/) was created in October of that year.

We didn't mention him by name in the last chapter, but a hidden hero of the last fifteen years of web standards is a man named [Domenic Denicola](https://blog.domenic.me/). He's currently the Staff Software Engineer at Google Tokyo, and he has been a voice behind many of the most prominent features in modern JavaScript. You've probably used something that he helped create. 

He helped usher in _Web Streams_ for instance which we will discuss in detail in the next chapter. Mr. Denicola has been a part of many other things, but we will obviously be focusing on promises in this chapter. He released his article ["You're Missing the Point of Promises"](https://blog.domenic.me/youre-missing-the-point-of-promises/) in late 2013 which helped clarify the idea that mutable implementations like jQuery's fell short of the ideal. 

Domenic stressed that much of the power of promises came from their ability to be chained together, and that each promise needed to be able to return a new promise. He was [one of the driving forces](https://www.youtube.com/watch?v=V2Q13hzTGmA) behind the new specification, and he helped create a rigorous test suite to ensure that all implementations were compliant. As we'll see in the next section, the modern API conforms closely to his 2013 paper ["States and Fates"](https://github.com/domenic/promises-unwrapping/blob/master/docs/states-and-fates.md). 


## A Simple Thenable

Some people said this [couldn't be done with just an EventTarget](https://www.xanthir.com/b4PY0)

There are five demos in total here. All of the modules are loaded into the browser as you click each button, so make sure you check out the browser console to see the logs that will get placed there. You can also click over to the editor to run the scripts there too if you want to play around with stuff.

In the first demo, we have a very simple `Thenable` class. Hopefully, this should make the basic concepts pretty easy to understand. However, this doesn't handle asynchronous tasks or chaining. So, I included another implementation which I worked on for _far too long_. I am fairly certain it is [complaint with the A+ spec](https://promisesaplus.com/)-- although it's hard to tell with all the _x_'s (tasks in my class).

The other three demos demonstrate the benefits of using native JavaScript Promises-- with the third demo going into the most detail. The fourth demo is meant to demonstrate the native interoperability with other `thenables` as it shows that our custom class works flawlessly when interwoven in a chain with real promises. The final demo further elucidates the limits of our custom class and the benefits of native promises.

<IFrame src="https://stackblitz.com/edit/thenables?ctl=1&embed=1&view=preview" />

## How and Why React Uses - Promises

### Chunks and Thenables

_Chunk_ and _Thenable_-- both of these words are used by the React team to define core aspects of the Server Components API. We just talked all about _Thenables_, and we'll learn more about chunks in the last chapter. 

So, these words are quite literal when we are talking about RSC's. When we talk about _Chunks_, you should think about small, individual units of work. Later, we will talk about webpack chunks. To distinguish these, note that streaming _RSC Chunks_ have a capital 'C'. To help understand what's happening here, let's take a look at [the code in the `react-server-dom-webpack/server.browser` file that we looked at earlier](https://github.com/vercel/next.js/blob/236075362a1ea368a625e887ef269e8af750fe1c/packages/next/src/compiled/react-server-dom-webpack/cjs/react-server-dom-webpack-server.browser.development.js#L2703) where they define the Chunk class.

<Chunk />

Don't worry if you don't fully get this just yet. We actually won't use this function in this chapter (this is used to encode the [_Flight Response_](./4-flight-response)). The important thing to understand here is that they sub-class the promise prototype and create their own custom `.then()` method. So, every single _Chunk_ is a _Thenable_. We're about to go deeper into the code, but this is very important to keep in mind as we go through this.

## Web Standards

To be clear, the Promises/A+ standard was widely respected immediately, but this was not part of the formal EcmaScript standardization process. Much like CommonJS with Promises/A, this specification was simply the result of a group of developers getting together to decide on a formal set of best practices. It was backed up by a rigorous test suite, but developers had to choose one of many libraries to use them. 

At this point, people had lost a bit of faith in groups like the W3C and TC39. From the very beginning, standards on the web have faced a bit of an uphill battle. For instance, [when Marc Andreessen first proposed the IMG tag](http://1997.webhistory.org/www.lists/www-talk.1993q1/0182.html), he pretty much ignored all the suggestions from his peers-- [even Tim Berners-Lee](http://1997.webhistory.org/www.lists/www-talk.1993q1/0186.html). In retrospect, this seems to have been [more of an announcement than a proposal](https://lunduke.substack.com/p/brendan-eich-interview-jan-9th-2018). Things got worse before they got better.

### Early EcmaScript

As I mentioned earlier, Microsoft won the browser wars fairly quickly. Internet Explorer was the dominant force in the market for a long time. This was a bit of a problem because Microsoft was not very interested in standardizing the language of JavaScript. Once Netscape had been extinguished, Microsoft preferred to use their monopoly to push their own proprietary technologies like ActiveX.

Before open-sourcing their code, Netscape did not go easily into the good night. Because Microsoft was perverting the language with incompatible additions to JScript, Netscape soon realized they needed to get serious about standardization. After their difficulty reverse-engineering the language, Microsoft seemed like they were ready to play ball. However, the [W3C was not interested in standardizing programming languages](https://www.madmode.com/2013/js-w3c-ecma.html), so [Ecma International](https://ecma-international.org/) was chosen instead.

The [first meeting](https://web.archive.org/web/19981203070212/http://cgi.netscape.com/newsref/pr/newsrelease289.html) was held in November 1996. As this was the 39th Technical Committee formed at Ecma International, the group was inventively called TC39. Due to [trademark issues](https://tinyclouds.org/trademark) with Sun, they were forced to name the official language EcmaScript. This name has been largely maligned as an unwanted annoyance, and Brendan Eich likened it to ["a skin disease"](https://web.archive.org/web/20110522170037/https://mail.mozilla.org/pipermail/es-discuss/2006-October/000133.html). 

Microsoft wrote a hurried draft document which the committee adopted as a starting point simply because [it used Microsoft Word which they preferred](https://www.wirfs-brock.com/allen/jshopl.pdf). They quickly agreed that host-specific things like the object model of each browser would be outside of the scope of the standard. After over eight months of bargaining, the first EcmaScript standard was released in June 1997-- nominally ending the initial year and a half of anarchy.

The first standard was rather basic as the primary goal was ensuring interoperability between the implementations. All new features were deferred to future versions. Within a year, the committee [released a second version](https://archives.ecma-international.org/1998/TC39/8T39-010.pdf) to gain full acceptance as an International Standards Organization (ISO) standard. In all, this only added a few minor corrections, Unicode support, and some changes to the Date object to prepare for Y2K.

The third edition was released on December 16th, 1999. Both Internet Explorer and Netscape were constantly innovating with new features during this entire time, and they were rarely compatible with each other. So, while this added things like closures, strict equality, _try-catch-finally_ and `RegExp` to the _de jure_ language, the committee was still playing catch-up to the _de facto_ implementations in the browsers. [Retro-specs](http://diveintohtml5.info/past.html) like this were unfortunately common at the time, but it was the only way to get the browsers to agree on anything.

### HTML 5

This was not restricted to TC-39 and standardizing EcmaScript. By 1998, people on the W3C were saying things like, ["The Future of HTML as we know it should be: Nasty, Brutish, and Short"](https://www.w3.org/MarkUp/future/papers/singer/im-164149.htm)

[Brendan Eich said this about WHATWG's intentions](https://web.archive.org/web/20130729234702/http://origin.conversationsnetwork.org/The%20Gillmor%20Gang%20-%20July%209%2C%202004.mp3).

> Authors know HTML and to some extent CSS... These tools are used by millions of people. Not all of them top programmers or designers, but there's nothing competing with [these tools] that I know of.... I think it's much likelier to say that you could get the web shifted incrementally towards richer content and application models than you could roll out a brave new world of XHTML and SVG and X-Forms... It's not just browser vendors wanting to satisfy their own codebase convenience, but we're always thinking of what the mass market of web authors want.

[On the first day](https://www.w3.org/2004/04/webapps-cdf-ws/minutes-20040601.html#topic18), one of the people leading the committee called [JavaScript, "the worst invention ever](https://www.phonk.net/Gedachten/JavaScript).

This was [voted down on the second day](https://www.w3.org/2004/04/webapps-cdf-ws/minutes-20040602.html#topic28.1).



The _WHATWG_, or Web Hypertext Application Technology Working Group, is a group who work together to create and update the rules for how HTML, the DOM, and [a few other things](https://spec.whatwg.org/) should work. Their job is to make sure the web stays modern and consistent for everyone.

### What Who?

As I discussed in [another article](../client-side-routing/2-a-brief-history-of-client-side-routing), the specifications for HTML and the DOM were initially formalized in 1994 by the [_W3C_](https://www.w3.org/), a consortium founded by Tim Berners-Lee. However, this group was quickly [stalled by corporate interests](https://www.reddit.com/r/javascript/comments/5swe9b/what_is_the_difference_between_the_w3c_and_the/) and derailed by things like an XHTML2 spec which was incompatible with much of the internet. So, [the _WHATWG_ was formed by several browser vendors](https://html.spec.whatwg.org/dev/introduction.html#history-2) in the name of pragmatism in June 2004 with a primary focus on backwards compatibility.

While the _W3C_ issued competing (unused) specs for many years, they eventually accepted the _WHATWG_ and [started working together with them in 2019](https://www.w3.org/blog/2019/w3c-and-whatwg-to-work-together-to-advance-the-open-web-platform/). The _WHATWG_ maintains living standards, and the _W3C_ periodically publishes yearly versions. The _W3C_ also still publish [a wide variety of other standards](https://www.w3.org/TR/). Groups like the [_CSSWG_](https://wiki.csswg.org/) and the [ARIA WG](https://www.w3.org/WAI/ARIA/) are very important for the web.

The _WHATWG_ maintain [living standards](https://spec.whatwg.org/) that intend to actually document how browsers actually work today. Generally, these are related to low-level activities like how browsers interact with JavaScript, process data, or make network requests. The [_DOM_](https://dom.spec.whatwg.org/) is the best example.

There are many other notable ones like the [_fetch_](https://fetch.spec.whatwg.org/) API and the topic of this article-- _Streams_.

### EcmaScript Harmony

By 2006, [Eich was trying again](https://mdn.dev/archives/media/presentations/xtech2006/javascript/index.html) with a new version of EcmaScript 4. He called it JavaScript 2, and it had a wide range features from [static types to packages and namespaces(https://evertpot.com/ecmascript-4-the-missing-version/).

Eich summarized the new ES Harmony process as [both quality and date driven](https://www.youtube.com/watch?v=1EyRscXrehw&t=394s).

[E4X Standard was passed in June 2004](https://www-archive.mozilla.org/js/language/ECMA-357.pdf).
[E4X is dead, and for very good reasons.](https://bugzilla.mozilla.org/show_bug.cgi?id=695577#c1)


## JSON Replacer and Reviver Functions

To understand what's actually happening here, we must briefly discuss the concept of a [JSON Replacer Function](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/JSON/stringify). This is the term used for the second argument in the `JSON.stringify` method. `JSON.stringify` is one of the most common ways to prepare a complex JavaScript value to be sent somewhere across the internet. This process is known as serialization. It transforms the value into a string that can be understood by the `JSON.parse` method on the other side and turned back into the original value.

`JSON.stringify` provides a very sensible default serialization algorithm which works for most cases. So, often people only provide one argument to the `JSON.stringify` method, or they skip to the third (which is for spacing) while ignoring the second. However, this second argument can be an extremely powerful function called the `replacer` that allows you to customize the serialization process.

This `replacer` function is called for every single property on the object being serialized. It is passed two arguments. The first is the key of the property, and the second is the value. The `replacer` function can then conditionally return new values in place of the original ones. If it returns `undefined`, that property will be omitted from the serialization process entirely. 

## How and Why React Uses - JSON methods

### resolveModelToJSON

Here's a simple demo where we look for a key of `thisThing` so we can change that value into something more exciting. Otherwise, we just return the original value.

Like I said, the `stringify` method has a default serialization that works for most cases. However, there are some values that cannot be serialized-- like `Symbol` or a `BigInt`. Additionally, `Date` objects are automatically serialized into strings. Even if you attempt to override this behavior with a `replacer` function, it won't work. I show this in the demo below. 

The only ways I could find to change this were pretty hacky-- like [overriding the `.toJSON` method on the `Date` object itself](https://stackoverflow.com/questions/31096130/how-to-json-stringify-a-javascript-date-and-preserve-timezone). Instead, React pulls a few other tricks. Let's start diving into `resolveModelToJSON` and take a look.

<IFrame src="https://stackblitz.com/edit/json-replacer-and-reviver-functions?ctl=1&embed=1&view=preview" />


## Task Scheduling

<IFrame src="https://stackblitz.com/edit/browser-event-loop?ctl=1&embed=1&view=preview" />

## How and Why React Uses - setImmediate

## Modern Standards

[As early as 2010](https://web.archive.org/web/20120820081926/http://piratepad.net/amwb-20101129), Brendan Eich was [publically expressing his love](http://brendaneich.com/2010/11/paren-free/) for [JavaScript compilers like CoffeeScript](https://brendaneich.com/2011/05/my-jsconf-us-presentation/). With this inspiration, he was imagining tools that would[automatically convert new JavaScript syntax into something compatible with older browsers](https://web.archive.org/web/20120314235839/http://www.aminutewithbrendan.com/pages/20110131).

### Extensible Web Manifesto

Only four months after Domenic Denicola released "You're Missing The Point of Promises", web legend [Alex Russell contributed the first commit](https://github.com/slightlyoff/Promises/commit/2d8729233bdcbf784fdbfe6d796ff67ae5ce1030) to the repository that ended up becoming EcmaScript Native Promises. This began as something called a [Future in the DOM spec](https://infrequently.org/2013/06/sfuturepromiseg/) for a bit. This was intended to avoid a namespace conflict because Russell was optimistic that something called Promise would end up in the language.

the terms deferred, promise, and future were [deeply entwined and commonly confused](https://stackoverflow.com/questions/6801283/what-are-the-differences-between-deferred-promise-and-future-in-javascript/18858041#18858041).

 included in the EcmaScript standard until [June of 2015](https://www.ecma-international.org/ecma-262/6.0/#sec-promise-objects).

### Mutation Observers

### Microtasks

### Generators and Async Iterators

[Brendan Eich first attempted to add them to Firefox in February 2006](https://bugzilla.mozilla.org/show_bug.cgi?id=326466). At NodeConf in 2011, he sold them as a solution for ["callback-free i/o"](https://brendaneich.com/2011/05/mozillas-nodeconf-presentation/)

### Async / Await

Soon after generators and promises arrived in ES6, people started discussing a way to make this syntax even nicer. Even though long chains of promises are much preferable to a gigantic pyramid of doom, they can still be a bit hard to read. People wanted to write asynchronous code that looked more like synchronous code. 

Essentially, this was an attempt to [bring coroutines to JavaScript](https://en.wikipedia.org/wiki/Coroutine). The basic idea is that you can pause the execution of a function, go do other things while you wait for something asynchronous to complete. Then, you can come right back into the context of the function where you were before. 

While a generator allowed developers to do this with the context of a single frame, an async function would allow you to do this with the entire call stack. This makes it extremely convenient to write ergonomic, concurrent code even if you need to wait for multiple things to happen in the same function. In [early 2014](https://github.com/tc39/proposal-async-await/commit/2c499feb41df4c79a884d1520518cd00ab623e5b), the first proposal for `async` / `await` was created. 

In truth, this is just some [syntax sugar around generators](https://tc39.es/proposal-async-await/#desugaring), but the authoring experience cannot be denied. You just add the `async` keyword to the function declaration. Then, every time you add the `await` keyword, the runtime will step out of the function until that promise resolves. 

Async functions always return a promise even if you don't use the `await` keyword. Like `process.nextTick`, this can be a simple way to make sure that something important happens before the next pass through the event loop. However, it's also critical to note that each `await` is processed one at a time, so it can be easy to slow things down [a bit too much](https://web.dev/async-functions/#careful-avoid-going-too-sequential).

### `queueMicrotask`

### `XMLHttpRequest`

### `fetch` and `AbortController`


<IFrame src="https://stackblitz.com/edit/thenables-fetch?ctl=1&embed=1&view=preview" />
## How and Why React Uses - fetch


<IFrame src="https://stackblitz.com/edit/react-data-demos?ctl=1&embed=1&view=preview" />

### `createFromFetch`

## Conclusion

If you want to read more about the history of JavaScript, I really recommend ["JavaScript: The First 20 Years"](https://www.wirfs-brock.com/allen/jshopl.pdf). It's a paper written for the [History of Programming Languages](https://dl.acm.org/conference/hopl) by Brendan Eich and Allen Wirfs-Brock-- the editor of ES5 and ES6. You can't get much more authoritative than that, and it provides a lot of fascinating context for the language.

There's also a [great series of talks by Douglas Crockford](https://www.youtube.com/watch?v=JxAXlJEmNMg) that looks at things from a slightly more opinionated angle. It's a bit more holistic in depth. And, if you don't have the attention span for either of those, here's [a short article from Sebastian Peyrott at Auth0](https://auth0.com/blog/a-brief-history-of-javascript) with some great videos of early Netscape in action. Additionally, there were so many fantastic links I included in this article that I hope you take the time to check out.